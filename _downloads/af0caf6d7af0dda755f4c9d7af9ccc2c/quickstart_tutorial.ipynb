{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JustZeed/Apprentissage_Par_Contrainte/blob/branch-1/_downloads/af0caf6d7af0dda755f4c9d7af9ccc2c/quickstart_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGn_QamwxWA-"
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1ptsF2TxWA-"
      },
      "source": [
        "[Learn the Basics](intro.html) \\|\\| **Quickstart** \\|\\|\n",
        "[Tensors](tensorqs_tutorial.html) \\|\\| [Datasets &\n",
        "DataLoaders](data_tutorial.html) \\|\\|\n",
        "[Transforms](transforms_tutorial.html) \\|\\| [Build\n",
        "Model](buildmodel_tutorial.html) \\|\\|\n",
        "[Autograd](autogradqs_tutorial.html) \\|\\|\n",
        "[Optimization](optimization_tutorial.html) \\|\\| [Save & Load\n",
        "Model](saveloadrun_tutorial.html)\n",
        "\n",
        "Quickstart\n",
        "==========\n",
        "\n",
        "This section runs through the API for common tasks in machine learning.\n",
        "Refer to the links in each section to dive deeper.\n",
        "\n",
        "Working with data\n",
        "-----------------\n",
        "\n",
        "PyTorch has two [primitives to work with\n",
        "data](https://pytorch.org/docs/stable/data.html):\n",
        "`torch.utils.data.DataLoader` and `torch.utils.data.Dataset`. `Dataset`\n",
        "stores the samples and their corresponding labels, and `DataLoader`\n",
        "wraps an iterable around the `Dataset`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "YOfoKFUbxWA_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOXIQ7YVxWBA"
      },
      "source": [
        "PyTorch offers domain-specific libraries such as\n",
        "[TorchText](https://pytorch.org/text/stable/index.html),\n",
        "[TorchVision](https://pytorch.org/vision/stable/index.html), and\n",
        "[TorchAudio](https://pytorch.org/audio/stable/index.html), all of which\n",
        "include datasets. For this tutorial, we will be using a TorchVision\n",
        "dataset.\n",
        "\n",
        "The `torchvision.datasets` module contains `Dataset` objects for many\n",
        "real-world vision data like CIFAR, COCO ([full list\n",
        "here](https://pytorch.org/vision/stable/datasets.html)). In this\n",
        "tutorial, we use the FashionMNIST dataset. Every TorchVision `Dataset`\n",
        "includes two arguments: `transform` and `target_transform` to modify the\n",
        "samples and labels respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "LKUCHkhPxWBA"
      },
      "outputs": [],
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z2ayeuuxWBA"
      },
      "source": [
        "We pass the `Dataset` as an argument to `DataLoader`. This wraps an\n",
        "iterable over our dataset, and supports automatic batching, sampling,\n",
        "shuffling and multiprocess data loading. Here we define a batch size of\n",
        "64, i.e. each element in the dataloader iterable will return a batch of\n",
        "64 features and labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "XsnaHQAqxWBB",
        "outputId": "66a5b67c-2c09-41e6-bcf8-c4fdd064c5be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OODofg3uxWBB"
      },
      "source": [
        "Read more about [loading data in PyTorch](data_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v24uS26lxWBB"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPZjymTTxWBB"
      },
      "source": [
        "Creating Models\n",
        "===============\n",
        "\n",
        "To define a neural network in PyTorch, we create a class that inherits\n",
        "from\n",
        "[nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html).\n",
        "We define the layers of the network in the `__init__` function and\n",
        "specify how data will pass through the network in the `forward`\n",
        "function. To accelerate operations in the neural network, we move it to\n",
        "the\n",
        "[accelerator](https://pytorch.org/docs/stable/torch.html#accelerators)\n",
        "such as CUDA, MPS, MTIA, or XPU. If the current accelerator is\n",
        "available, we will use it. Otherwise, we use the CPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "8WNQcMxzxWBC",
        "outputId": "80bd3c7d-124e-4019-e51a-ef1c24dfe58d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=784, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 28*28)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUFLnoecxWBC"
      },
      "source": [
        "Read more about [building neural networks in\n",
        "PyTorch](buildmodel_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MZDb-ObxWBC"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RMlTQZPxWBC"
      },
      "source": [
        "Optimizing the Model Parameters\n",
        "===============================\n",
        "\n",
        "To train a model, we need a [loss\n",
        "function](https://pytorch.org/docs/stable/nn.html#loss-functions) and an\n",
        "[optimizer](https://pytorch.org/docs/stable/optim.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "g7xJz3uTxWBC"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFrD1SERxWBC"
      },
      "source": [
        "In a single training loop, the model makes predictions on the training\n",
        "dataset (fed to it in batches), and backpropagates the prediction error\n",
        "to adjust the model\\'s parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "y1zayQdpxWBC"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        pred = pred.view(X.shape)\n",
        "        loss = loss_fn(pred, X)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "603Qv-RdxWBD"
      },
      "source": [
        "We also check the model\\'s performance against the test dataset to\n",
        "ensure it is learning.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "orkFwxH2xWBD"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    # correct = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            pred = pred.view(X.shape)\n",
        "            test_loss += loss_fn(pred, X).item()\n",
        "            # correct += (pred.flatten().argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    # correct /= size\n",
        "    # print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gF8a5V7xWBD"
      },
      "source": [
        "The training process is conducted over several iterations (*epochs*).\n",
        "During each epoch, the model learns parameters to make better\n",
        "predictions. We print the model\\'s accuracy and loss at each epoch;\n",
        "we\\'d like to see the accuracy increase and the loss decrease with every\n",
        "epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "nOqc3xw4xWBD",
        "outputId": "d7ce1bb7-c0c5-41bf-eb40-ccc77aa4e827",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 0.210572  [   64/60000]\n",
            "loss: 0.022400  [ 6464/60000]\n",
            "loss: 0.017474  [12864/60000]\n",
            "loss: 0.014326  [19264/60000]\n",
            "loss: 0.013333  [25664/60000]\n",
            "loss: 0.012174  [32064/60000]\n",
            "loss: 0.010648  [38464/60000]\n",
            "loss: 0.009416  [44864/60000]\n",
            "loss: 0.008838  [51264/60000]\n",
            "loss: 0.009214  [57664/60000]\n",
            "Test Error: \n",
            " Avg loss: 0.009030 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.008672  [   64/60000]\n",
            "loss: 0.008731  [ 6464/60000]\n",
            "loss: 0.008366  [12864/60000]\n",
            "loss: 0.007371  [19264/60000]\n",
            "loss: 0.007411  [25664/60000]\n",
            "loss: 0.007101  [32064/60000]\n",
            "loss: 0.006630  [38464/60000]\n",
            "loss: 0.006318  [44864/60000]\n",
            "loss: 0.006075  [51264/60000]\n",
            "loss: 0.006555  [57664/60000]\n",
            "Test Error: \n",
            " Avg loss: 0.006491 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.006257  [   64/60000]\n",
            "loss: 0.006465  [ 6464/60000]\n",
            "loss: 0.005618  [12864/60000]\n",
            "loss: 0.005732  [19264/60000]\n",
            "loss: 0.005860  [25664/60000]\n",
            "loss: 0.005552  [32064/60000]\n",
            "loss: 0.005299  [38464/60000]\n",
            "loss: 0.005027  [44864/60000]\n",
            "loss: 0.005038  [51264/60000]\n",
            "loss: 0.005333  [57664/60000]\n",
            "Test Error: \n",
            " Avg loss: 0.005582 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.005340  [   64/60000]\n",
            "loss: 0.005355  [ 6464/60000]\n",
            "loss: 0.004619  [12864/60000]\n",
            "loss: 0.004861  [19264/60000]\n",
            "loss: 0.004863  [25664/60000]\n",
            "loss: 0.004659  [32064/60000]\n",
            "loss: 0.004560  [38464/60000]\n",
            "loss: 0.004671  [44864/60000]\n",
            "loss: 0.004537  [51264/60000]\n",
            "loss: 0.004706  [57664/60000]\n",
            "Test Error: \n",
            " Avg loss: 0.005162 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.004949  [   64/60000]\n",
            "loss: 0.004732  [ 6464/60000]\n",
            "loss: 0.004340  [12864/60000]\n",
            "loss: 0.004501  [19264/60000]\n",
            "loss: 0.004365  [25664/60000]\n",
            "loss: 0.004174  [32064/60000]\n",
            "loss: 0.004218  [38464/60000]\n",
            "loss: 0.004511  [44864/60000]\n",
            "loss: 0.004028  [51264/60000]\n",
            "loss: 0.004435  [57664/60000]\n",
            "Test Error: \n",
            " Avg loss: 0.005253 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7y82huvxWBD"
      },
      "source": [
        "Read more about [Training your model](optimization_tutorial.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTqvUU5ixWBD"
      },
      "source": [
        "------------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vxm1sx6xWBD"
      },
      "source": [
        "Saving Models\n",
        "=============\n",
        "\n",
        "A common way to save a model is to serialize the internal state\n",
        "dictionary (containing the model parameters).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "H8OshMADxWBD",
        "outputId": "e388f3da-e5e6-4812-aaba-5f21d17ecb81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eQyGt6XxWBD"
      },
      "source": [
        "Loading Models\n",
        "==============\n",
        "\n",
        "The process for loading a model includes re-creating the model structure\n",
        "and loading the state dictionary into it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "Cf5coCW2xWBD",
        "outputId": "dfffedf2-640d-4352-838a-0199b50165c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uCZBMDdxWBD"
      },
      "source": [
        "This model can now be used to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "VB_P6gQtxWBE",
        "outputId": "5337794d-6d25-47ff-c32d-7f64a31b4dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "number = 0\n",
        "x, y = test_data[number][0], test_data[number][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    x = x.unsqueeze(0)\n",
        "    pred = model(x)\n",
        "    reconstructed_image = pred.view(x.shape)\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
        "\n",
        "    axes[0].imshow(x.squeeze().cpu().numpy(), cmap='gray')\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(reconstructed_image.squeeze().cpu().numpy(), cmap='gray')\n",
        "    axes[1].set_title('Reconstructed Image')\n",
        "    axes[1].axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUyPoTBqxWBE"
      },
      "source": [
        "Read more about [Saving & Loading your\n",
        "model](saveloadrun_tutorial.html).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}